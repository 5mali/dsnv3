{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from os.path import dirname, abspath, join\n",
    "from os import getcwd\n",
    "import sys\n",
    "\n",
    "THIS_DIR = getcwd()\n",
    "CLASS_DIR = abspath(join(THIS_DIR, 'dsnclasses'))  #abspath(join(THIS_DIR, '../../..', 'dsnclasses'))\n",
    "sys.path.append(CLASS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 161\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENO(object):\n",
    "    \n",
    "    #no. of forecast types is 6 ranging from 0 to 5\n",
    "  \n",
    "    def __init__(self, location='tokyo', year=2010, shuffle=False, day_balance=False):\n",
    "        self.location = location\n",
    "        self.year = year\n",
    "        self.day = None\n",
    "        self.hr = None\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.day_balance = day_balance\n",
    "\n",
    "        self.TIME_STEPS = None #no. of time steps in one episode\n",
    "        self.NO_OF_DAYS = None #no. of days in one year\n",
    "        \n",
    "        self.NO_OF_DAYTYPE = 5 #no. of daytypes\n",
    "        self.daycounter = 0 #to count number of days that have been passed\n",
    "        \n",
    "        self.sradiation = None #matrix with GSR for the entire year\n",
    "        self.senergy = None #matrix with harvested energy data for the entire year\n",
    "        self.fforecast = None #matrix with forecast values for each day\n",
    "        \n",
    "\n",
    "        self.henergy = None #harvested energy variable\n",
    "        self.fcast = None #forecast variable\n",
    "        self.sorted_days = [] #days sorted according to day type\n",
    "        \n",
    "        self.SMAX = 1000 # 1 Watt Solar Panel\n",
    "\n",
    "    \n",
    "    #function to get the solar data for the given location and year and prep it\n",
    "    def get_data(self):\n",
    "        #CSV files contain the values of GSR (Global Solar Radiation in MegaJoules per meters squared per hour)\n",
    "        THIS_DIR = getcwd()\n",
    "        DATA_DIR = abspath(join(THIS_DIR, 'data'))  #abspath(join(THIS_DIR, '../../..', 'data'))\n",
    "        file = DATA_DIR + '/' + self.location +'/' + str(self.year) + '.csv'\n",
    "        #skiprows=4 to remove unnecessary title texts\n",
    "        #usecols=4 to read only the Global Solar Radiation (GSR) values\n",
    "        solar_radiation = pd.read_csv(file, skiprows=4, encoding='shift_jisx0213', usecols=[4])\n",
    "        \n",
    "        #convert dataframe to numpy array\n",
    "        solar_radiation = solar_radiation.values\n",
    "        #reshape solar_radiation into no_of_daysx24 array\n",
    "        sradiation = solar_radiation.reshape(-1,24)\n",
    "        #convert missing data in CSV files to zero\n",
    "        sradiation[np.isnan(sradiation)] = 0\n",
    "        if(self.shuffle): #if class instatiation calls for shuffling the day order. Required when learning\n",
    "            np.random.shuffle(sradiation) \n",
    "        self.sradiation = sradiation\n",
    "        \n",
    "        \n",
    "        #GSR values (in MJ/sq.mts per hour) need to be expressed in mW\n",
    "        # Conversion is accomplished by \n",
    "        # solar_energy = GSR(in MJ/m2/hr) * 1e6 * size of solar cell * efficiency of solar cell /(60x60) *1000 (to express in mW)\n",
    "        # the factor of 2 in the end is assuming two solar cells\n",
    "        self.senergy = 2*self.sradiation * 1e6 * (55e-3 * 70e-3) * 0.15 * 1000/(60*60)\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    #function to map total day radiation into type of day ranging from 0 to 5\n",
    "    #the classification into day types is quite arbitrary. There is no solid logic behind this type of classification.\n",
    "    \n",
    "    def get_day_state(self,tot_day_radiation):\n",
    "        if (tot_day_radiation < 3.5):\n",
    "            day_state = 0\n",
    "        elif (3.5 <= tot_day_radiation < 7):\n",
    "            day_state = 1\n",
    "        elif (7 <= tot_day_radiation < 12):\n",
    "            day_state = 2\n",
    "        elif (12 <= tot_day_radiation < 15):\n",
    "            day_state = 3\n",
    "        elif (15 <= tot_day_radiation < 17.5):\n",
    "            day_state = 4\n",
    "        else:\n",
    "            day_state = 5\n",
    "        return int(day_state)\n",
    "    \n",
    "    def get_forecast(self):\n",
    "        #create a perfect forecaster.\n",
    "        tot_day_radiation = np.sum(self.sradiation, axis=1) #contains total solar radiation for each day\n",
    "        get_day_state = np.vectorize(self.get_day_state)\n",
    "        self.fforecast = get_day_state(tot_day_radiation)\n",
    "        \n",
    "        #sort days depending on the type of day and shuffle them; maybe required when learning\n",
    "        for fcast in range(0,6):\n",
    "            fcast_days = ([i for i,x in enumerate(self.fforecast) if x == fcast])\n",
    "            np.random.shuffle(fcast_days)\n",
    "            self.sorted_days.append(fcast_days)\n",
    "        return 0\n",
    "    \n",
    "    def reset(self,day=0): #it is possible to reset to the beginning of a certain day\n",
    "        \n",
    "        self.get_data() #first get data for the given year\n",
    "        self.get_forecast() #calculate the forecast\n",
    "        \n",
    "        self.TIME_STEPS = self.senergy.shape[1]\n",
    "        self.NO_OF_DAYS = self.senergy.shape[0]\n",
    "        \n",
    "        self.day = day\n",
    "        self.hr = 0\n",
    "        \n",
    "        self.henergy = self.senergy[self.day][self.hr]\n",
    "        self.fcast = self.fforecast[self.day]\n",
    "        \n",
    "        end_of_day = False\n",
    "        end_of_year = False\n",
    "        return [self.henergy, self.fcast, end_of_day, end_of_year]\n",
    "\n",
    "    \n",
    "    def step(self):\n",
    "        end_of_day = False\n",
    "        end_of_year = False\n",
    "        if not(self.day_balance): #if daytype balance is not required\n",
    "            if(self.hr < self.TIME_STEPS - 1):\n",
    "                self.hr += 1\n",
    "                self.henergy = self.senergy[self.day][self.hr] \n",
    "            else:\n",
    "                if(self.day < self.NO_OF_DAYS -1):\n",
    "                    end_of_day = True\n",
    "                    self.hr = 0\n",
    "                    self.day += 1\n",
    "                    self.henergy = self.senergy[self.day][self.hr] \n",
    "                    self.fcast = self.fforecast[self.day]\n",
    "                else:\n",
    "                    end_of_day = True\n",
    "                    end_of_year = True\n",
    "                    \n",
    "        else: #when training, we want all daytypes to be equally represented for robust policy\n",
    "              #obviously, the days are going to be in random order\n",
    "            if(self.hr < self.TIME_STEPS - 1):\n",
    "                self.hr += 1\n",
    "                self.henergy = self.senergy[self.day][self.hr] \n",
    "            else:\n",
    "                if(self.daycounter < self.NO_OF_DAYS -1):\n",
    "                    end_of_day = True\n",
    "                    self.daycounter += 1\n",
    "                    self.hr = 0\n",
    "                    daytype = random.choice(np.arange(0,self.NO_OF_DAYTYPE)) #choose random daytype\n",
    "                    self.day = np.random.choice(self.sorted_days[daytype]) #choose random day from that daytype\n",
    "                    self.henergy = self.senergy[self.day][self.hr] \n",
    "                    self.fcast = self.fforecast[self.day]\n",
    "                else: \n",
    "                    end_of_day = True\n",
    "                    end_of_year = True\n",
    "                    self.daycounter = 0\n",
    "        \n",
    "        \n",
    "        return [self.henergy, self.fcast, end_of_day, end_of_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAPM (object):\n",
    "    def __init__(self,location='tokyo', year=2010, shuffle=False, trainmode=False):\n",
    "\n",
    "        #all energy values i.e. BMIN, BMAX, BOPT, HMAX are in mWhr. Assuming one timestep is one hour\n",
    "        \n",
    "        self.BMIN = 0.0                #Minimum battery level that is tolerated. Maybe non-zero also\n",
    "        self.BMAX = 9250.0            #Max Battery Level. May not necessarily be equal to total batter capacity [3.6V x 2500mAh]\n",
    "        self.BOPT = 0.5 * self.BMAX    #Optimal Battery Level. Assuming 50% of battery is the optimum\n",
    "        \n",
    "        self.HMIN = 0      #Minimum energy that can be harvested by the solar panel.\n",
    "        self.HMAX = None   #Maximum energy that can be harvested by the solar panel. [500mW]\n",
    "        \n",
    "        self.DMAX = 500      #Maximum energy that can be consumed by the node in one time step. [~ 3.6V x 135mA]\n",
    "        self.N_ACTIONS = 10  #No. of different duty cycles possible\n",
    "        self.DMIN = self.DMAX/self.N_ACTIONS #Minimum energy that can be consumed by the node in one time step. [~ 3.6V x 15mA]\n",
    "        \n",
    "        self.binit = None     #battery at the beginning of day\n",
    "        self.btrack = []      #track the mean battery level for each day\n",
    "        self.atrack = []      #track the duty cycles for each day\n",
    "        self.batt = None      #battery variable\n",
    "        self.enp = None       #enp at end of hr\n",
    "        self.henergy = None   #harvested energy variable\n",
    "        self.fcast = None     #forecast variable\n",
    "        \n",
    "        self.location = location\n",
    "        self.year = year\n",
    "        self.shuffle = shuffle\n",
    "        self.trainmode = trainmode\n",
    "        self.eno = None#ENO(self.location, self.year, shuffle=shuffle, day_balance=trainmode) #if trainmode is enable, then days are automatically balanced according to daytype i.e. day_balance= True\n",
    "        \n",
    "        self.violation_flag = False\n",
    "        self.violation_counter = 0\n",
    "\n",
    "        self.no_of_day_state = 6;\n",
    " \n",
    "    def reset(self,day=0,batt=-1):\n",
    "        henergy, fcast, day_end, year_end = self.eno.reset(day) #reset the eno environment\n",
    "        self.violation_flag = False\n",
    "        self.violation_counter = 0\n",
    "        if(batt == -1):\n",
    "            self.batt = self.BOPT\n",
    "        else:\n",
    "            self.batt = batt\n",
    "            \n",
    "        self.batt = np.clip(self.batt, self.BMIN, self.BMAX)\n",
    "        self.binit = self.batt\n",
    "        self.btrack = np.append(self.btrack, self.batt) #track battery levels\n",
    "\n",
    "#         self.enp = self.BOPT - self.batt\n",
    "        self.enp = self.binit - self.batt #enp is calculated\n",
    "        self.henergy = np.clip(henergy, self.HMIN, self.HMAX) #clip henergy within HMIN and HMAX\n",
    "        self.fcast = fcast\n",
    "        \n",
    "        norm_batt = self.batt/self.BMAX\n",
    "        norm_enp = self.enp/(self.BMAX/2)\n",
    "        norm_henergy = self.henergy/self.HMAX\n",
    "#         norm_fcast = self.fcast/(self.no_of_day_state-1)\n",
    "\n",
    "        c_state = [norm_batt, norm_enp, norm_henergy] #continuous states\n",
    "        reward = 0\n",
    "        \n",
    "        return [c_state, reward, day_end, year_end]\n",
    "    \n",
    "    def getstate(self): #query the present state of the system\n",
    "        norm_batt = self.batt/self.BMAX\n",
    "        norm_enp = self.enp/(self.BMAX/2)\n",
    "        norm_henergy = self.henergy/self.HMAX\n",
    "#         norm_fcast = self.fcast/(self.no_of_day_state-1)\n",
    "        c_state = [norm_batt, norm_enp, norm_henergy] #continuous states\n",
    "\n",
    "        return c_state\n",
    "    \n",
    "#     def rewardfn(self):\n",
    "#         R_PARAM = 20000 #chosen empirically for best results\n",
    "#         mu = 0\n",
    "#         sig = 0.05*R_PARAM #knee curve starts at approx. 2000mWhr of deviation\n",
    "        \n",
    "#         if(np.abs(self.enp) <= 0.12*R_PARAM):\n",
    "#             norm_reward = 4*(np.exp(-np.power((self.enp - mu)/sig, 2.)/2) / np.exp(-np.power((0 - mu)/sig, 2.)/2))\n",
    "#         else:\n",
    "#             norm_reward = -0.25 - 2.5*np.abs(self.enp/R_PARAM)\n",
    "#         return (norm_reward)/2\n",
    "        \n",
    "    \n",
    "    #reward function\n",
    "    def rewardfn(self):\n",
    "        \n",
    "        #FIRST REWARD AS A FUNCTION OF DRIFT OF BMEAN FROM BOPT i.e. in terms of BDEV = |BMEAN-BOPT|/BMAX\n",
    "        bmean = np.mean(self.btrack)\n",
    "        bdev = np.abs(self.BOPT - bmean)/self.BMAX\n",
    "        # based on the sigmoid function\n",
    "        # bdev ranges from bdev = (0,0.5) of BMAX\n",
    "        p1_sharpness = 10\n",
    "        n1_sharpness = 20\n",
    "        shift1 = 0.5\n",
    "        # r1(x) = 0.5 when x = 0.25. \n",
    "        # Therefore, shift = 0.5 to make sure that (2*x-shift) evaluates to zero at x = 0.25\n",
    "\n",
    "        if(bdev<=0.25): \n",
    "            r1 = 2*(1-(1 / (1 + np.exp(-p1_sharpness*(2*bdev-shift1)))))-1\n",
    "        else: \n",
    "            r1 = 2*(1-(1 / (1 + np.exp(-n1_sharpness*(2*bdev-shift1)))))-1\n",
    "        # r1 ranges from -1 to 1\n",
    "            \n",
    "        #SECOND REWARD AS A FUNCTION OF ENP AS LONG AS BMAX/4 <= batt <= 3*BMAX/4 i.e. bdev <= 0.25\n",
    "        if(bdev <=0.25):\n",
    "            # enp ranges from enp = (0,3) of DMAX\n",
    "            p2_sharpness = 2\n",
    "            n2_sharpness = 2\n",
    "            shift2 = 6    \n",
    "            # r1(x) = 0.5 when x = 2. \n",
    "            # Therefore, shift = 6 to make sure that (3*x-shift) evaluates to zero at x = 2\n",
    "#             print('Day energy', np.sum(self.eno.senergy[self.eno.day]))\n",
    "#             print('Node energy', np.sum(self.atrack)*self.DMAX/self.N_ACTIONS)\n",
    "#             x = np.abs(np.sum(self.eno.senergy[self.eno.day])-np.sum(self.atrack)*self.DMAX/self.N_ACTIONS )/self.DMAX\n",
    "            x = np.abs(self.enp/self.DMAX)\n",
    "            if(x<=2): \n",
    "                r2 = (1 / (1 + np.exp(p2_sharpness*(3*x-shift2))))\n",
    "            else: \n",
    "                r2 = (1 / (1 + np.exp(n2_sharpness*(3*x-shift2))))\n",
    "        else:\n",
    "            r2 = 0 # if mean battery lies outside bdev limits, then enp reward is not considered.\n",
    "        # r2 ranges from 0 to 1\n",
    "\n",
    "        #REWARD AS A FUNCTION OF BATTERY VIOLATIONS\n",
    "        if(self.violation_flag):\n",
    "            violation_penalty = 2\n",
    "        else:\n",
    "            violation_penalty = 0 #penalty for violating battery limits anytime during the day\n",
    "        \n",
    "#         print(\"Reward \", (r1 + r2 - violation_penalty), '\\n')\n",
    "        return (r1 + r2 - violation_penalty)\n",
    "    \n",
    "    def step(self, action):\n",
    "        day_end = False\n",
    "        year_end = False\n",
    "        reward = 0\n",
    "       \n",
    "        action = np.clip(action, 0, self.N_ACTIONS-1) #action values range from (0 to N_ACTIONS-1)\n",
    "        self.atrack = np.append(self.atrack, action+1) #track duty cycles\n",
    "        e_consumed = (action+1)*self.DMAX/self.N_ACTIONS   #energy consumed by the node\n",
    "        \n",
    "        self.batt += (self.henergy - e_consumed)\n",
    "        if(self.batt <= self.BMIN or self.batt >= self.BMAX ):\n",
    "            if(self.violation_flag == False): \n",
    "                self.violation_counter += 1\n",
    "            self.violation_flag = True #penalty for violating battery limits anytime during the day\n",
    "        self.batt = np.clip(self.batt, self.BMIN, self.BMAX) #clip battery values within permitted level\n",
    "        self.btrack = np.append(self.btrack, self.batt) #track battery levels\n",
    "\n",
    "#         self.enp = self.BOPT - self.batt \n",
    "        self.enp = self.binit - self.batt\n",
    "        \n",
    "        #proceed to the next time step\n",
    "        self.henergy, self.fcast, day_end, year_end = self.eno.step()\n",
    "        self.henergy = np.clip(self.henergy, self.HMIN, self.HMAX) #clip henergy within HMIN and HMAX\n",
    "\n",
    "        if(day_end): #if eno object flags that the day has ended then give reward\n",
    "            reward = self.rewardfn()\n",
    "             \n",
    "            if (self.trainmode): #reset battery to optimal level if limits are exceeded when training\n",
    "#                 self.batt = np.random.uniform(0,1)*self.BMAX\n",
    "                if (self.violation_flag):\n",
    "                  self.batt = self.BOPT  \n",
    "            \n",
    "            self.violation_flag = False\n",
    "            self.binit = self.batt #this will be the new initial battery level for next day\n",
    "            self.btrack = [] #clear battery tracker\n",
    "            self.atrack = [] #clear duty cycle tracker\n",
    "                    \n",
    "                \n",
    "        norm_batt = self.batt/self.BMAX\n",
    "        norm_enp = self.enp/(self.BMAX/2)\n",
    "        norm_henergy = self.henergy/self.HMAX\n",
    "        norm_fcast = self.fcast/5\n",
    "\n",
    "        c_state = [norm_batt, norm_enp, norm_henergy] #continuous states\n",
    "        return [c_state, reward, day_end, year_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "BATCH_SIZE = 24\n",
    "LR = 0.01          # learning rate\n",
    "EPSILON = 0.9               # greedy policy\n",
    "GAMMA = 0.9                 # reward discount\n",
    "LAMBDA = 0.9                # parameter decay\n",
    "TARGET_REPLACE_ITER = 24*7*4*9    # target update frequency (every two months)\n",
    "MEMORY_CAPACITY     = 24*7*4*12*3      # store upto six month worth of memory   \n",
    "\n",
    "N_ACTIONS = 10 #no. of duty cycles (0,1,2,3,4)\n",
    "N_STATES = 3 #number of state space parameter [batt, enp, henergy]\n",
    "\n",
    "HIDDEN_LAYER = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Class definitions for NN model and learning algorithm\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(N_STATES, HIDDEN_LAYER)\n",
    "        self.fc1.weight.data.normal_(0, 0.01)   # initialization\n",
    "        \n",
    "#         self.fc2 = nn.Linear(HIDDEN_LAYER, HIDDEN_LAYER)\n",
    "#         self.fc2.weight.data.normal_(0, 0.1)   # initialization\n",
    "        \n",
    "#         self.fc3 = nn.Linear(HIDDEN_LAYER, HIDDEN_LAYER)\n",
    "#         self.fc3.weight.data.normal_(0, 0.1)   # initialization\n",
    "\n",
    "        self.out = nn.Linear(HIDDEN_LAYER, N_ACTIONS)\n",
    "        self.out.weight.data.normal_(0, 0.1)   # initialization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        actions_value = self.out(x)\n",
    "        return actions_value\n",
    "    \n",
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        self.eval_net, self.target_net = Net(), Net()\n",
    "#         print(\"Neural net\")\n",
    "#         print(self.eval_net)\n",
    "\n",
    "        self.learn_step_counter = 0                                     # for target updating\n",
    "        self.memory_counter = 0                                         # for storing memory\n",
    "        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))     # initialize memory [mem: ([s], a, r, [s_]) ]\n",
    "        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR)\n",
    "        self.loss_func = nn.MSELoss()\n",
    "\n",
    "    def choose_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "        if np.random.uniform() < EPSILON:   # greedy\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "            action = action[0] # return the argmax index\n",
    "        else:   # random\n",
    "            action = np.random.randint(0, N_ACTIONS)\n",
    "            action = action\n",
    "        return action\n",
    "    \n",
    "    def choose_greedy_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "    \n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "        action = action[0] # return the argmax index\n",
    "\n",
    "        return action\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        transition = np.hstack((s, [a, r], s_))\n",
    "        # replace the old memory with new memory\n",
    "        index = self.memory_counter % MEMORY_CAPACITY\n",
    "        self.memory[index, :] = transition\n",
    "        self.memory_counter += 1\n",
    "    \n",
    "    def store_day_transition(self, transition_rec):\n",
    "        data = transition_rec\n",
    "        index = self.memory_counter % MEMORY_CAPACITY\n",
    "        self.memory= np.insert(self.memory, index, data,0)\n",
    "        self.memory_counter += transition_rec.shape[0]\n",
    "\n",
    "    def learn(self):\n",
    "        # target parameter update\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        # sample batch transitions\n",
    "        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)\n",
    "        b_memory = self.memory[sample_index, :]\n",
    "        b_s = torch.FloatTensor(b_memory[:, :N_STATES])\n",
    "        b_a = torch.LongTensor(b_memory[:, N_STATES:N_STATES+1].astype(int))\n",
    "        b_r = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])\n",
    "\n",
    "        # q_eval w.r.t the action in experience\n",
    "        q_eval = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n",
    "        q_next = self.target_net(b_s_).detach()     # detach from graph, don't backpropagate\n",
    "        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)   # shape (batch, 1)\n",
    "        loss = self.loss_func(q_eval, q_target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN USING data from TOKYO, WAKKANAI, MINAMIDAITO  FROM 2005 to 2015 on pre-trained model\n",
    "#Simulating actual working\n",
    "#No Random Battery \n",
    "#No battery reset\n",
    "#No Shuffle\n",
    "#No day_balance\n",
    "dqn = DQN()\n",
    "old = dqn.eval_net.fc1.weight.data.numpy().flatten()\n",
    "old2 = old\n",
    "\n",
    "NO_OF_ITERATIONS = 5\n",
    "\n",
    "best_iteration = -1\n",
    "best_avg_reward = -1000 #initialize best average reward to very low value\n",
    "reset_flag = True #put CAPM in traimode\n",
    "reset_counter = 0 #count number of times the battery had to be reset\n",
    "# PFILENAME = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(8)) #create random filename\n",
    "# BFILENAME = \"best\"+PFILENAME + \".pt\" #this file stores the best model\n",
    "# TFILENAME = \"terminal\"+PFILENAME + \".pt\" #this file stores the last model\n",
    "\n",
    "avg_reward_rec = [] #record the yearly average rewards over the entire duration of training\n",
    "violation_rec = []\n",
    "print('\\nTRAINING IN PROGRESS\\n')\n",
    "Y_EAR = 2004\n",
    "for iteration in range(NO_OF_ITERATIONS):\n",
    "    LOCATION = 'tokyo' # random.choice(['tokyo','wakkanai','minamidaito'])\n",
    "    YEAR = 2009#Y_EAR + iteration%11#random.choice(np.arange(2005,2015))\n",
    "    capm = CAPM(LOCATION,YEAR,shuffle=False, trainmode=reset_flag) #instantiate the CAPM class\n",
    "    capm.eno = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "    capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "#     clear_output()\n",
    "    print('Iteration {}:  {}, {} '.format(iteration, LOCATION.upper(), YEAR))\n",
    "    print('EPSILON = {}, LR = {}, RST_FLAG = {}'.format(EPSILON, LR, reset_flag))\n",
    "\n",
    "    \n",
    "\n",
    "    s, r, day_end, year_end = capm.reset()\n",
    "    yr_record = np.empty(4)\n",
    "\n",
    "    record = np.empty(4) #record for battery, henergy, reward and action\n",
    "    transition_rec = np.zeros((capm.eno.TIME_STEPS, N_STATES * 2 + 2)) #record all the transition in one day\n",
    "\n",
    "    while True:\n",
    "        a = dqn.choose_action(s)\n",
    "\n",
    "        # present state = [batt, enp, henergy]\n",
    "        record = np.vstack((record, [s[0],s[2],r, a])) # record battery, henergy, reward and action for troubleshooting\n",
    "                                                       # However, we are interested only in the reward\n",
    "        yr_record = np.vstack((yr_record, [s[0],s[2],r, a]))\n",
    "\n",
    "        # take action\n",
    "        s_, r, day_end, year_end = capm.step(a)\n",
    "        \n",
    "        temp_transitions = np.hstack((s, [a, r], s_))\n",
    "        transition_rec[capm.eno.hr-1,:] = temp_transitions\n",
    "\n",
    "        if (day_end):\n",
    "            transition_rec[:,5] = r #broadcast reward to all states\n",
    "            decay_factor = [i for i in (LAMBDA**n for n in reversed(range(0, capm.eno.TIME_STEPS)))]\n",
    "            transition_rec[:,5] = transition_rec[:,5] * decay_factor #decay reward proportionately\n",
    "            dqn.store_day_transition(transition_rec)\n",
    "#             if (capm.BMIN == capm.batt or capm.BMAX == capm.batt):\n",
    "#                 capm.batt = capm.BOPT\n",
    "\n",
    "        if dqn.memory_counter > MEMORY_CAPACITY:\n",
    "            dqn.learn()\n",
    "#             print(\"Learning:\",capm.eno.year, capm.eno.day)\n",
    "\n",
    "        if (year_end):\n",
    "    #             print(\"End of Year\")\n",
    "            break\n",
    "\n",
    "        # transition to new state\n",
    "        s = s_\n",
    "\n",
    "    record = np.delete(record, 0, 0) #remove the first row which is garbage\n",
    "    reward_rec = record[:,2] #extract reward information from the record array\n",
    "    reward_rec = reward_rec[reward_rec != 0] #remove all zero rewards in the middle of the days\n",
    "    print(\"Average Reward \\t\\t= {:8.3f}\".format(np.mean(reward_rec)))\n",
    "    print(\"Violation Counter \\t= {}\".format(capm.violation_counter))\n",
    "\n",
    "#     if(best_avg_reward < np.mean(reward_rec)):\n",
    "#         best_avg_reward = np.mean(reward_rec)\n",
    "    \n",
    "#     if(best_avg_reward > 1.5 or iteration > 20):\n",
    "#         EPSILON = 0.9\n",
    "#         LR = 0.01\n",
    "        \n",
    "#     if (capm.violation_counter < 5):\n",
    "#         reset_flag = False\n",
    "#         EPSILON = 0.95\n",
    "#         LR = 0.001\n",
    "        \n",
    "\n",
    "#     # Check if reward beats the High Score and possible save it    \n",
    "#     if (iteration > 19): #save the best models only after 20 iterations\n",
    "#         print(\"Best Score \\t = {:8.3f} @ Iteration No. {}\".format(best_avg_reward, best_iteration))\n",
    "#         if(best_avg_reward < np.mean(reward_rec)):\n",
    "#             best_iteration = iteration\n",
    "#             best_avg_reward = np.mean(reward_rec)\n",
    "#             print(\"Saving Model\")\n",
    "#             torch.save(dqn.eval_net.state_dict(), BFILENAME)\n",
    "#     else:\n",
    "#         print(\"\\r\")\n",
    "    # Log the average reward in avg_reward_rec\n",
    "    avg_reward_rec = np.append(avg_reward_rec, np.mean(reward_rec))\n",
    "    violation_rec = np.append(violation_rec, capm.violation_counter)\n",
    "\n",
    "    yr_record = np.delete(yr_record, 0, 0) #remove the first row which is garbage\n",
    "#     NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "#     yr_reward_rec = yr_record[:,2]\n",
    "#     yr_reward_rec = yr_reward_rec[yr_reward_rec != 0]\n",
    "    fig = plt.figure(figsize=(24,3))\n",
    "    plt.plot(yr_record[:,0],'r')\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "\n",
    "    new = dqn.eval_net.fc1.weight.data.numpy().flatten()\n",
    "    plt.plot(old2,color='r', alpha=0.4)\n",
    "    plt.plot(old,color='r')\n",
    "    plt.plot(new,color='b')\n",
    "    old2 = old\n",
    "    old = new\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # End of training\n",
    "# Save the last model\n",
    "# torch.save(dqn.eval_net.state_dict(), TFILENAME) \n",
    "\n",
    "# Plot the average reward log\n",
    "plt.plot(avg_reward_rec,'k')\n",
    "plt.ylim([-3,1]);\n",
    "plt.show()\n",
    "\n",
    "#Plot the violation record log\n",
    "plt.plot(violation_rec,'g')\n",
    "plt.ylim([0,365]);\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #BFILENAME -> loads the best model\n",
    "# #TFILENAME -> loads the last model\n",
    "# MODELFILE = BFILENAME\n",
    "# TEST_LOCATION = 'tokyo'\n",
    "# dqn = DQN()\n",
    "# for TEST_YEAR in np.arange(2015,2018):\n",
    "#     test_model(TEST_LOCATION, TEST_YEAR, MODELFILE, dqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #BFILENAME -> loads the best model\n",
    "# #TFILENAME -> loads the last model\n",
    "# MODELFILE = TFILENAME\n",
    "# TEST_LOCATION = 'tokyo'\n",
    "# dqn = DQN()\n",
    "# for TEST_YEAR in np.arange(2016,2018)\n",
    "#     test_model(TEST_LOCATION, TEST_YEAR, MODELFILE, dqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_YEAR = 2018\n",
    "# for TEST_LOCATION in ['tokyo','wakkanai','minamidaito']:\n",
    "#     test_model(TEST_LOCATION, TEST_YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dqn = DQN()\n",
    "# capm = CAPM(TEST_LOCATION,TEST_YEAR, shuffle=False, trainmode=False) #if reset is True\n",
    "# capm.eno = ENO(TEST_LOCATION,TEST_YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "# capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "\n",
    "# # load the required model\n",
    "# dqn.eval_net.load_state_dict(torch.load(MODELFILE))\n",
    "# dqn.eval_net.eval()\n",
    "# print('Model Used: ',MODELFILE)\n",
    "\n",
    "# s, r, day_end, year_end = capm.reset()\n",
    "# yr_test_record = np.empty(4)\n",
    "\n",
    "# while True:\n",
    "#     a = dqn.choose_greedy_action(s)\n",
    "\n",
    "#     #state = [batt, enp, henergy, fcast]\n",
    "#     yr_test_record = np.vstack((yr_test_record, [s[0],s[2],r, a])) #record battery, henergy, reward and action\n",
    "\n",
    "#     # take action\n",
    "#     s_, r, day_end, year_end = capm.step(a)\n",
    "    \n",
    "# #     if day_end:\n",
    "# #         if (capm.BMIN ==capm.batt or capm.batt == capm.BMAX):\n",
    "# #             capm.batt = capm.BOPT\n",
    "        \n",
    "\n",
    "#     if year_end:\n",
    "#         print(\"End of Test\")\n",
    "#         break\n",
    "\n",
    "#     s = s_\n",
    "\n",
    "# yr_test_record = np.delete(yr_test_record, 0, 0) #remove the first row which is garbage\n",
    "\n",
    "# #Plot the reward and battery for the entire year run\n",
    "# title = TEST_LOCATION.upper() + ',' + str(TEST_YEAR)\n",
    "\n",
    "# NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "# yr_test_reward_rec = yr_test_record[:,2]\n",
    "# yr_test_reward_rec = yr_test_reward_rec[yr_test_reward_rec != 0]\n",
    "# print('Average Reward for',title, '=', np.mean(yr_test_reward_rec))\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(24,10))\n",
    "# fig.suptitle(title, fontsize=15)\n",
    "\n",
    "# #     ax1 = fig.add_subplot(211)\n",
    "# #     ax1.plot(yr_test_reward_rec)\n",
    "# #     ax1.set_title(\"\\n\\nYear Run Reward\")\n",
    "# #     ax1.set_ylim([-3,1])\n",
    "\n",
    "# ax2 = fig.add_subplot(111)\n",
    "# ax2.plot(yr_test_record[:,0],'r')\n",
    "# ax2.set_title(\"\\n\\nYear Run Battery\")\n",
    "# ax2.set_ylim([0,1])\n",
    "# plt.sca(ax2)\n",
    "# plt.xticks(np.arange(0, NO_OF_DAYS*24, 50*24),np.arange(0,NO_OF_DAYS,50))\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot the reward and battery for the entire year run on a day by day basis\n",
    "# title = TEST_LOCATION.upper() + ',' + str(TEST_YEAR)\n",
    "# TIME_AXIS = np.arange(0,capm.eno.TIME_STEPS)\n",
    "# for DAY in range(150,170):#capm.eno.NO_OF_DAYS):\n",
    "#     START = DAY*24\n",
    "#     END = START+24\n",
    "\n",
    "#     daytitle = title + ' - DAY ' + str(DAY)\n",
    "#     fig = plt.figure(figsize=(16,4))\n",
    "#     st = fig.suptitle(daytitle)\n",
    "\n",
    "#     ax2 = fig.add_subplot(121)\n",
    "#     ax2.plot(yr_test_record[START:END,1],'g')\n",
    "#     ax2.set_title(\"HARVESTED ENERGY\")\n",
    "#     plt.xlabel(\"Hour\")\n",
    "#     ax2.set_ylim([0,1])\n",
    "\n",
    "#     #plot battery for year run\n",
    "#     ax1 = fig.add_subplot(122)\n",
    "#     ax1.plot(TIME_AXIS,yr_test_record[START:END,0],'r') \n",
    "# #     ax1.plot(TIME_AXIS, np.ones(capm.eno.TIME_STEPS)*capm.BOPT/capm.BMAX,'r--')\n",
    "#     ax1.plot(TIME_AXIS, np.ones(capm.eno.TIME_STEPS)*yr_test_record[START,0],'r--')\n",
    "#     ax1.text(0.1, 0.2, \"BINIT = %.2f\\n\" %(yr_test_record[START,0]),fontsize=11, ha='left')\n",
    "#     ax1.text(0.1, 0.4, \"TENP = %.2f\\n\" %(capm.BOPT/capm.BMAX-yr_test_record[END,0]),fontsize=11, ha='left')\n",
    "#     ax1.text(0.1, 0.3, \"BMEAN = %.2f\\n\" %(np.mean(yr_test_record[START:END,0])),fontsize=11, ha='left')\n",
    "\n",
    "\n",
    "\n",
    "#     ax1.set_title(\"YEAR RUN TEST\")\n",
    "#     if END < (capm.eno.NO_OF_DAYS*capm.eno.TIME_STEPS):\n",
    "#         ax1.text(0.1, 0, \"REWARD = %.2f\\n\" %(yr_test_record[END,2]),fontsize=13, ha='left')\n",
    "#     plt.xlabel(\"Hour\")\n",
    "#     ax1.set_ylabel('Battery', color='r',fontsize=12)\n",
    "#     ax1.set_ylim([0,1])\n",
    "\n",
    "#     #plot actions for year run\n",
    "#     ax1a = ax1.twinx()\n",
    "#     ax1a.plot(yr_test_record[START:END,3])\n",
    "#     ax1a.set_ylim([0,N_ACTIONS])\n",
    "#     ax1a.set_ylabel('Duty Cycle', color='b',fontsize=12)\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     st.set_y(0.95)\n",
    "#     fig.subplots_adjust(top=0.75)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'fc2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-49e582206d2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 532\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'fc2'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dqn.eval_net.fc1.weight.data.numpy().flatten(),color='r')\n",
    "plt.plot(dqn.eval_net.fc2.weight.data.numpy().flatten(),color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
